\documentclass{article} % For LaTeX2e
% We will use NIPS submission format
\usepackage{nips13submit_e,times}
% for hyperlinks
\usepackage{hyperref}
\usepackage{url}
% For figures
\usepackage{graphicx} 
\usepackage{subfigure} 
% math packages
\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{amsopn}
\usepackage{ifthen}
\usepackage{natbib}

\title{Project-I by Group MexicoCity}

\author{
Kevin Serrano\\EPFL\\
\texttt{kevin.serrano@epfl.ch} \And Youssef El Baba\\EPFL\\
\texttt{youssef.baba@epfl.ch} \And Alexandre Helfre\\EPFL\\
\texttt{alexandre.helfre@epfl.ch}
}

% The \author macro works with any number of authors. There are two commands
% used to separate the names and addresses of multiple authors: \And and \AND.
%
% Using \And between authors leaves it to \LaTeX{} to determine where to break
% the lines. Using \AND forces a linebreak at that point. So, if \LaTeX{}
% puts 3 of 4 authors names on the first line, and the last on the second
% line, try using \AND instead of \And before the third author name.

\nipsfinalcopy 

\begin{document}

\maketitle

\begin{abstract}
In this report, we discuss our implementation and findings for the project-I. \textcolor{red}{Todo at the end}


\end{abstract}
\section{Five functions}
\begin{itemize}
\item \textit{leastSquaresGD(y,tX,alpha)} : Least squares using gradient descent, alpha is the step-size
\item \textit{leastSquares(y,tX)} : Least squares using normal equations
\item \textit{ridgeRegression(y,tX,lambda)} : Ridge regression using normal equations, lambda is the regularization coefficient
\item \textit{logisticRegression(y,tX,alpha)} : Logistic regression using gradient descent or Newton's method
\item \textit{penLogisticRegression(y,tX,alpha,lambda)} : Penalized logistic regression 

\end{itemize}
These functions are different machine learning methods.

\textcolor{red}{Formula? Not even sure this section is useful}

\section{Data observation}
We have two data set. One for regression and one for classification. \begin{description}
\item[Regression] Consists of output variables $\mathbf{y}$ and input variables $\mathbf{X}$. The number of example is $N = 1400$ and each input $\mathbf{x_n}$ has dimensionality $D = 48$. The first $34$ are real valued and the last $14$ are categorical.
\item[Classification]

\end{description}


\section{Data visualization and cleaning}
\textcolor{red}{Histogram, correlation, applied methods}


\section{Best method : Ridge Regression}
\textcolor{red}{explain what is the best method and why for our dataset, add some figures and results}
\section{Feature transformations}
\textcolor{red}{Different transformation (myPoly, sqrt, etc)}
\section{Summary}
\textcolor{red}{summarize in a few lines and write down all the final results}


\subsubsection*{Acknowledgments}


\subsubsection*{References}

\end{document}
